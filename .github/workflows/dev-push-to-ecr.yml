name: Build, Push to ECR, and Deploy front end and backend to ECS 
on:
  push:
    branches: 
      - dev
env: 
  POSTGRES_SERVER: ${{ secrets.POSTGRES_SERVER }}
  POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
  POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
  POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_REGION: ${{ secrets.AWS_REGION }}
  FIRST_SUPERUSER: ${{ secrets.FIRST_SUPERUSER }}
  FIRST_SUPERUSER_NAME: ${{ secrets.FIRST_SUPERUSER_NAME }}
  FIRST_SUPERUSER_PASSWORD: ${{ secrets.FIRST_SUPERUSER_PASSWORD }}
  PROJECT_NAME: ${{ secrets.PROJECT_NAME }}
  ECR_REPOSITORY_BACKEND: ${{ secrets.ECR_REPOSITORY_BACKEND }}
  ENVIRONMENT: ${{ secrets.ENVIRONMENT }}
  TAG: latest
  ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_BACKEND }}
  ECS_CLUSTER: ${{ secrets.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-cluster
  ECS_SERVICE: ${{ secrets.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-service
  ECS_TASK_DEFINITION: ${{ secrets.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-task
  CONTAINER_NAME: ${{ secrets.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-container



jobs:
  build-and-deploy-app:
    runs-on: self-hosted  
    environment: DEV 
    steps:
    - name: Install Docker and Docker Compose
      run: |
        sudo dnf update -y
        sudo dnf install docker -y
        sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo systemctl start docker
        sudo systemctl enable docker
        sudo usermod -aG docker $USER
        sudo chown $USER:docker /var/run/docker.sock
        sudo chmod +x /usr/local/bin/docker-compose
        docker --version
        docker-compose --version
        docker version
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{env.AWS_ACCESS_KEY_ID}} 
        aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY}}
        aws-region: ${{ env.AWS_REGION }}
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
   
    # - name: Build, tag, and push frontend image to Amazon ECR
    #   env:
    #     ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
    #     IMAGE_TAG: latest 
    #   run: |
    #     # Create ECR repository if it doesn't exist
    #     repo_name="${ENVIRONMENT}-${PROJECT_NAME}-frontend"
    #     aws ecr describe-repositories --repository-names "${repo_name}" || aws ecr create-repository --repository-name "${repo_name}"
    #
    #     # Set environment variables for docker-compose
    #     export DOCKER_IMAGE_FRONTEND="${ENVIRONMENT}-${PROJECT_NAME}-frontend"
    #     export TAG="${TAG}"
    #
    #     # Build the frontend image
    #     docker-compose build frontend 
    #
    #     # Tag the image with ECR repository
    #     docker tag "${DOCKER_IMAGE_FRONTEND}:${TAG}" "${ECR_REGISTRY}/${repo_name}:${IMAGE_TAG}"
    #
    #     # Push the image to ECR
    #     docker push "${ECR_REGISTRY}/${repo_name}:${IMAGE_TAG}"
    #
    # - name: Build, tag, and push backend image to Amazon ECR
    #   env:
    #     ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
    #     IMAGE_TAG: latest 
    #   run: |
    #     # Create ECR repository if it doesn't exist
    #     repo_name="${ENVIRONMENT}-${PROJECT_NAME}-backend"
    #     aws ecr describe-repositories --repository-names "${repo_name}" || aws ecr create-repository --repository-name "${repo_name}"
    #
    #     # Set environment variables for docker-compose
    #     export DOCKER_IMAGE_BACKEND="${ENVIRONMENT}-${PROJECT_NAME}-backend"
    #     export TAG="${TAG}"
    #
    #     # Build the backend image
    #     docker-compose build backend
    #
    #     # Tag the image with ECR repository
    #     docker tag "${DOCKER_IMAGE_BACKEND}:${TAG}" "${ECR_REGISTRY}/${repo_name}:${IMAGE_TAG}"
    #
    #     # Push the image to ECR
    #     docker push "${ECR_REGISTRY}/${repo_name}:${IMAGE_TAG}"   

    - name: Create or Update ECS Task Execution Role
      run: |
        ROLE_NAME="${{ env.ENVIRONMENT }}-${{ env.PROJECT_NAME }}-ecs-execution-role"
        POLICY_ARN="arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
        
        # Check if the role already exists
        if aws iam get-role --role-name $ROLE_NAME 2>/dev/null; then
          echo "Role $ROLE_NAME already exists. Updating..."
          
          # Update the assume role policy document
          aws iam update-assume-role-policy --role-name $ROLE_NAME --policy-document '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "Service": "ecs-tasks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }
            ]
          }'
        else
          echo "Creating new role $ROLE_NAME..."
          # Create the role
          aws iam create-role --role-name $ROLE_NAME --assume-role-policy-document '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "Service": "ecs-tasks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }
            ]
          }'
        fi
        
        # Check if the policy is already attached
        if ! aws iam list-attached-role-policies --role-name $ROLE_NAME --query "AttachedPolicies[?PolicyArn=='$POLICY_ARN'].PolicyArn" --output text | grep -q "$POLICY_ARN"; then
          echo "Attaching policy $POLICY_ARN to role $ROLE_NAME..."
          # Attach the necessary policy
          aws iam attach-role-policy --role-name $ROLE_NAME --policy-arn $POLICY_ARN
        else
          echo "Policy $POLICY_ARN is already attached to role $ROLE_NAME."
        fi
        
        # Get the role ARN
        ROLE_ARN=$(aws iam get-role --role-name $ROLE_NAME --query 'Role.Arn' --output text)
        echo "ECS_EXECUTION_ROLE_ARN=$ROLE_ARN" >> $GITHUB_ENV

    - name: Deploy Network Stack
      run: |
        echo "ENV: ${ENVIRONMENT}"
        echo "PROJECT: ${PROJECT_NAME}"
        aws cloudformation deploy \
          --template-file infrastructure/network-resources.yml \
          --stack-name ${ENVIRONMENT}-${PROJECT_NAME}-network \
          --parameter-overrides \
            EnvironmentName=${ENVIRONMENT} \
            ProjectName=${PROJECT_NAME} \
          --capabilities CAPABILITY_IAM

    - name: Create ECS Cluster
      run: |
        echo "Creating ECS Cluster: ${{ env.ECS_CLUSTER }}"
        aws ecs create-cluster \
          --cluster-name ${{ env.ECS_CLUSTER }} \
          --capacity-providers FARGATE \
          --default-capacity-provider-strategy capacityProvider=FARGATE,weight=1

    - name: Create Task Definition
      run: |
        task_def=$(cat <<EOF
        {
          "family": "${{ env.ECS_TASK_DEFINITION }}",
          "networkMode": "awsvpc",
          "requiresCompatibilities": ["FARGATE"],
          "cpu": "256",
          "memory": "512",
          "executionRoleArn": "${{ env.ECS_EXECUTION_ROLE_ARN }}",
          "containerDefinitions": [
            {
              "name": "${{ env.CONTAINER_NAME }}",
              "image": "${{ env.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY }}:${{ env.TAG }}",
              "portMappings": [
                {
                  "containerPort": 80,
                  "hostPort": 80,
                  "protocol": "tcp"
                }
              ],
              "environment": [
                {"name": "POSTGRES_SERVER", "value": "${{ secrets.POSTGRES_SERVER }}"},
                {"name": "POSTGRES_USER", "value": "${{ secrets.POSTGRES_USER }}"},
                {"name": "POSTGRES_PASSWORD", "value": "${{ secrets.POSTGRES_PASSWORD }}"},
                {"name": "POSTGRES_DB", "value": "${{ secrets.POSTGRES_DB }}"},
                {"name": "POSTGRES_PORT", "value": "${{ secrets.POSTGRES_PORT }}"},
                {"name": "FIRST_SUPERUSER", "value": "${{ secrets.FIRST_SUPERUSER }}"},
                {"name": "SECRET_KEY", "value": "${{ secrets.SECRET_KEY }}"},
                {"name": "OPENAI_API_KEY", "value": "${{ secrets.OPENAI_API_KEY }}"},
                {"name": "ANTHROPIC_API_KEY", "value": "${{ secrets.ANTHROPIC_API_KEY }}"},
                {"name": "FIRST_SUPERUSER_PASSWORD", "value": "${{ secrets.FIRST_SUPERUSER_PASSWORD }}"},
                {"name": "PROJECT_NAME", "value": "${{ secrets.PROJECT_NAME }}"},
                {"name": "ENVIRONMENT", "value": "${{ secrets.ENVIRONMENT }}"}
              ],
              "logConfiguration": {
                "logDriver": "awslogs",
                "options": {
                  "awslogs-group": "/ecs/${{ env.ECS_TASK_DEFINITION }}",
                  "awslogs-region": "${{ env.AWS_REGION }}",
                  "awslogs-stream-prefix": "ecs"
                }
              }
            }
          ]
        }
        EOF
        )
        echo '$task_def' > task-definition.json
        aws ecs register-task-definition --cli-input-json file://task-definition.json

    - name: Create or Update Load Balancer
      run: |
        VPC_ID=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='VpcId'].OutputValue" --output text)
        SUBNET_1=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet1'].OutputValue" --output text)
        SUBNET_2=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet2'].OutputValue" --output text)
        SECURITY_GROUP=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='ECSSecurityGroup'].OutputValue" --output text)

        LB_NAME="${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-alb"
        LB_ARN=$(aws elbv2 describe-load-balancers --names $LB_NAME --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "")
        if [ -z "$LB_ARN" ] || [ "$LB_ARN" == "None" ]; then
          echo "Creating new load balancer: $LB_NAME"
          LB_ARN=$(aws elbv2 create-load-balancer \
            --name $LB_NAME \
            --subnets $SUBNET_1 $SUBNET_2 \
            --security-groups $SECURITY_GROUP \
            --query 'LoadBalancers[0].LoadBalancerArn' \
            --output text)
        else
          echo "Load balancer already exists: $LB_NAME"
        fi

        TG_NAME="${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-tg"
        TG_ARN=$(aws elbv2 describe-target-groups --names $TG_NAME --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "")
        if [ -z "$TG_ARN" ] || [ "$TG_ARN" == "None" ]; then
          echo "Creating new target group: $TG_NAME"
          TG_ARN=$(aws elbv2 create-target-group \
            --name $TG_NAME \
            --protocol HTTP \
            --port 80 \
            --vpc-id $VPC_ID \
            --target-type ip \
            --query 'TargetGroups[0].TargetGroupArn' \
            --output text)
        else
          echo "Target group already exists: $TG_NAME"
        fi

        LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn $LB_ARN --query 'Listeners[0].ListenerArn' --output text 2>/dev/null || echo "")
        if [ -z "$LISTENER_ARN" ] || [ "$LISTENER_ARN" == "None" ]; then
          echo "Creating new listener for load balancer"
          aws elbv2 create-listener \
            --load-balancer-arn $LB_ARN \
            --protocol HTTP \
            --port 80 \
            --default-actions Type=forward,TargetGroupArn=$TG_ARN
        else
          echo "Listener already exists for load balancer"
        fi

        echo "LB_ARN=$LB_ARN" >> $GITHUB_ENV
        echo "TG_ARN=$TG_ARN" >> $GITHUB_ENV

    - name: Create or Update ECS Service
      run: |
        SUBNET_1=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet1'].OutputValue" --output text)
        SUBNET_2=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet2'].OutputValue" --output text)
        SECURITY_GROUP=$(aws cloudformation describe-stacks --stack-name ${{ env.ENVIRONMENT }}-${{ secrets.PROJECT_NAME }}-network --query "Stacks[0].Outputs[?OutputKey=='ECSSecurityGroup'].OutputValue" --output text)

        if aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} --query "services[?status=='ACTIVE']" --output text | grep -q .; then
          aws ecs update-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service ${{ env.ECS_SERVICE }} \
            --task-definition ${{ env.ECS_TASK_DEFINITION }} \
            --desired-count 1 \
            --force-new-deployment
        else
          aws ecs create-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service-name ${{ env.ECS_SERVICE }} \
            --task-definition ${{ env.ECS_TASK_DEFINITION }} \
            --desired-count 1 \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_1,$SUBNET_2],securityGroups=[$SECURITY_GROUP],assignPublicIp=ENABLED}" \
            --load-balancers "targetGroupArn=$TG_ARN,containerName=${{ env.CONTAINER_NAME }},containerPort=80"
        fi

    - name: Get Load Balancer DNS Name
      run: |
        LB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns $LB_ARN --query 'LoadBalancers[0].DNSName' --output text)
        echo "Your API is accessible at: http://$LB_DNS"
        echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV

    - name: Cleanup
      if: always()
      run: |
        docker-compose down
